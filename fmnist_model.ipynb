{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x277b487d188>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "\n",
    "torch.set_printoptions(linewidth = 150)\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 10, kernel_size = 5, padding = (1,1))\n",
    "        self.bn1 = nn.BatchNorm2d(10)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 10, out_channels = 20, kernel_size = 4, padding = (1,1))\n",
    "        self.bn2 = nn.BatchNorm2d(20)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 20, out_channels = 40, kernel_size = 3, padding = (1,1))\n",
    "        self.bn3 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = 40*3*3, out_features = 180)\n",
    "        self.bn4 = nn.BatchNorm1d(180)\n",
    "        self.fc2 = nn.Linear(in_features = 180, out_features = 90)\n",
    "        self.bn5 = nn.BatchNorm1d(90)\n",
    "        self.out = nn.Linear(in_features = 90, out_features = 10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        t = self.bn1(t)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        t = self.bn2(t)\n",
    "        \n",
    "        t = F.relu(self.conv3(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        t = self.bn3(t)\n",
    "        \n",
    "        t = F.relu(self.fc1(t.reshape(-1, 40*3*3)))\n",
    "        t = self.bn4(t)\n",
    "        \n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.bn5(t)\n",
    "        \n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        \n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "            \n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "        \n",
    "    def begin_run(self, run, network, loader):\n",
    "        \n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment = f' -{run}')\n",
    "        \n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.network, images.to(getattr(run,'device', 'cpu')))\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        \n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss/len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct/len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accracy', accuracy, self.epoch_count)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "            \n",
    "        results = OrderedDict()\n",
    "        results['run'] = self.run_count\n",
    "        results['epoch'] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results['accuracy'] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
    "        \n",
    "        clear_output(wait = True)\n",
    "        display(df)\n",
    "        \n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item()*self.loader.batch_size\n",
    "        \n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim = 1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, filename):\n",
    "        \n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data,\n",
    "            orient = 'columns'\n",
    "        ).to_csv(f'{filename}.csv')\n",
    "        \n",
    "        with open(f'{filename}.json','w', encoding = 'utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii = False, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the dataset\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './datasets',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(train_set, batch_size = len(train_set), num_workers = 1)\n",
    "data = next(iter(loader))\n",
    "mean = data[0].mean()\n",
    "std = data[0].std()\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset with normalization\n",
    "\n",
    "train_set_normalized = torchvision.datasets.FashionMNIST(\n",
    "    root = './datasets',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [0.011],\n",
    "    batch_size = [1000],\n",
    "    device = ['cuda']\n",
    ")\n",
    "\n",
    "num_epochs = 30\n",
    "m = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    device = torch.device(run.device)\n",
    "    network = Network().to(device)\n",
    "    loader = DataLoader(train_set_normalized, batch_size = run.batch_size, num_workers = 1)\n",
    "    optimizer = optim.Adam(network.parameters(), lr = run.lr)\n",
    "\n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        m.begin_epoch()\n",
    "        \n",
    "        for batch in loader:        ## get batch\n",
    "            \n",
    "            images = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "            preds = network(images)  ## pass batch\n",
    "            loss = F.cross_entropy(preds, labels)   ## calculate loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()  ## calculate gradients\n",
    "            optimizer.step()  #update weights\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        \n",
    "        m.end_epoch()\n",
    "    \n",
    "    m.end_run()\n",
    "\n",
    "m.save('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the network\n",
    "\n",
    "PATH = 'networks/network.pt'\n",
    "torch.save(network.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the test_set\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './datasets',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2868), tensor(0.3524))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_test = DataLoader(test_set, batch_size = len(test_set), num_workers = 1)\n",
    "data_test = next(iter(loader_test))\n",
    "mean_test = data_test[0].mean()\n",
    "std_test = data_test[0].std()\n",
    "mean_test, std_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testset with normalization\n",
    "\n",
    "test_set_normalized = torchvision.datasets.FashionMNIST(\n",
    "    root = './datasets',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean_test, std_test)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the network\n",
    "\n",
    "path = 'networks/network.pt'\n",
    "net = Network().cuda()\n",
    "net.load_state_dict(torch.load(path))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing\n",
    "\n",
    "loader_test = DataLoader(test_set_normalized, batch_size = 1000, num_workers = 1)\n",
    "\n",
    "device_test = torch.device('cuda')\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "\n",
    "for batch_test in loader_test:\n",
    "    \n",
    "    images = batch_test[0].to(device_test)\n",
    "    labels = batch_test[1].to(device_test)\n",
    "    preds_test = net(images)  ## pass batch\n",
    "    loss_test = F.cross_entropy(preds_test, labels) \n",
    "    \n",
    "    total_loss += loss_test.item()*loader.batch_size\n",
    "    total_correct += preds_test.argmax(dim = 1).eq(labels).sum().item()\n",
    "    \n",
    "print(total_loss)\n",
    "print('accuracy:', total_correct/len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN_pytorch_FashionMNIST\n",
    "The CNN is built using CNN. It uses the FashionMNIST dataset which was built on the platform of MNIST dataset. The dataset contains a collection of 70,000 pictures (1, 28, 28) of dress, foot-wears etc. The CNN achieves nearly 97% accuracy in training set and 90% accuracy in test set with 50 epochs trained on one GPU.\n",
    "\n",
    "The CNN uses two convolution layers and three fully connected layers. Two special classes - RunBuilder & RunManager were built to test various netoworks with different set of hyperparameters. These classes have also been incorporated in the code. Any new parameter can be easily added using the params dictionary and making few changes. The RunManager class stores the values for each run which can be used in tensorboard to visualize the impact of changing hyperparameters. The results are also saved in a .csv and .json file to be utilized later. This class also enables the user to visualize the accuracy with respect to parameters in real time while training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test with an example\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "imsize = 28\n",
    "loader_ex = transforms.Compose([\n",
    "    transforms.Resize(imsize),  # scale imported image\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "image = Image.open('__.jpg')  ## image directory goes here __\n",
    "x = TF.to_grayscale(image)\n",
    "x = loader_ex(x)\n",
    "idx = net(x.unsqueeze(0).cuda()).argmax(dim = 1)[0]\n",
    "classes = test_set.classes\n",
    "print(classes[idx])\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
